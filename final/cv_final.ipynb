{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXqIoQ6iGm0J"
      },
      "source": [
        "#path settings\n",
        "import os\n",
        "drive_path = \"/content/drive/MyDrive/cv_final\"\n",
        "data_path = \"data/testing\"\n",
        "output_path = \"output/testing\"\n",
        "\n",
        "#first task 0_center_frame\n",
        "task_1_dir = os.path.join(drive_path,data_path,\"0_center_frame\")\n",
        "task_1_output = os.path.join(drive_path,output_path,\"0_center_frame\")\n",
        "\n",
        "# second task 1_30fps_to_240fps\n",
        "task_2_dir = os.path.join(drive_path,data_path,\"1_30fps_to_240fps\")\n",
        "task_2_output = os.path.join(drive_path,output_path,\"1_30fps_to_240fps\")\n",
        "\n",
        "# third task 2_24fps_to_60fps\n",
        "task_3_dir = os.path.join(drive_path,data_path,\"2_24fps_to_60fps\")\n",
        "task_3_output = os.path.join(drive_path,output_path,\"2_24fps_to_60fps\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psae3s3jEIBt",
        "outputId": "0691e33f-7856-431a-8438-d0e25adcd214"
      },
      "source": [
        "#確認GPU\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "name, driver_version, memory.total [MiB]\n",
            "Tesla T4, 460.32.03, 15109 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmGBdz1gEKI6",
        "outputId": "74f4767b-7091-40dd-e9c5-36844ea655c9"
      },
      "source": [
        "#GMA package\n",
        "!git clone https://github.com/brianchung0803/GMA.git\n",
        "!pip install einops\n",
        "%cd GMA/core/\n",
        "\n",
        "# Environment settings\n",
        "import sys\n",
        "\n",
        "sys.path.append('core')\n",
        "\n",
        "import argparse\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from network import RAFTGMA\n",
        "from utils import flow_viz\n",
        "from utils.utils import InputPadder\n",
        "from skimage import data,exposure,img_as_float\n",
        "from PIL import Image,ImageFilter\n",
        "\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "def load_image(imfile):\n",
        "    img = np.array(Image.open(imfile)).astype(np.uint8)\n",
        "    img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
        "    return img[None].to(DEVICE)\n",
        "\n",
        "\n",
        "def viz(img, flo, flow_dir):\n",
        "    img = img[0].permute(1, 2, 0).cpu().numpy()\n",
        "    flo = flo[0].permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # map flow to rgb image\n",
        "    flo = flow_viz.flow_to_image(flo)\n",
        "    cv2_imshow(flo)\n",
        "\n",
        "    imageio.imwrite(os.path.join(flow_dir, 'flo.png'), flo)\n",
        "    print(f\"Saving optical flow visualisation at {os.path.join(flow_dir, 'flo.png')}\")\n",
        "\n",
        "\n",
        "def normalize(x):\n",
        "    return x / (x.max() - x.min())\n",
        "\n",
        "\n",
        "args = {'model': '/content/GMA/checkpoints/gma-things.pth',\n",
        "        'model_name': 'GMA',\n",
        "        'path': '/content/drive/MyDrive/cv_final_project/data/data/validation/0_center_frame/5/input',\n",
        "        'num_heads': 1,\n",
        "        'position_only': False,\n",
        "        'position_and_content': False,\n",
        "        'mixed_precision': False}\n",
        "\n",
        "\n",
        "def get_optflow_GMA(img0_path, img1_path, show=False):\n",
        "    args = {'model': '/content/GMA/checkpoints/gma-things.pth', \n",
        "            'model_name': 'GMA',\n",
        "            'num_heads': 1,\n",
        "            'position_only': False,\n",
        "            'position_and_content': False,\n",
        "            'mixed_precision': False}\n",
        "    \n",
        "    model = torch.nn.DataParallel(RAFTGMA(args))\n",
        "    model.load_state_dict(torch.load(args['model']))\n",
        "\n",
        "    model = model.module\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        img0 = load_image(img0_path)\n",
        "        img1 = load_image(img1_path)\n",
        "        ###sharpen###\n",
        "        #kernel = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
        "        #img0 = torch.FloatTensor(  np.transpose(cv2.filter2D(np.array(PIL.Image.open(img0_path)), -1, kernel),[2,0,1])[np.newaxis,]  ).cuda()\n",
        "        #img1 = torch.FloatTensor(  np.transpose(cv2.filter2D(np.array(PIL.Image.open(img1_path)), -1, kernel),[2,0,1])[np.newaxis,]  ).cuda()\n",
        "        ###sharpen###\n",
        "        b, c, h, w = img0.shape\n",
        "        padder = InputPadder(img0.shape)\n",
        "        img0, img1 = padder.pad(img0, img1)\n",
        "        flow_low, flow_up = model(img0, img1, iters=12, test_mode=True)\n",
        "        flow_up = flow_up[0].permute(1, 2, 0).cpu().numpy()\n",
        "        flow_up = cv2.resize(flow_up, (w, h))\n",
        "        \n",
        "        if show:\n",
        "            flow_up = flow_viz.flow_to_image(flow_up)\n",
        "            cv2_imshow(flow_up)\n",
        "\n",
        "        # 回傳optical flow\n",
        "        return flow_up\n",
        "\n",
        "%cd ../../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'GMA' already exists and is not an empty directory.\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "/content/GMA/core\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqq-7lPJEWXP"
      },
      "source": [
        "#backward warping\n",
        "from torch.autograd import Variable\n",
        "class backWarp(torch.nn.Module):  \n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def forward(self, x, flo, boolv):\n",
        "        B, C, H, W = x.size()\n",
        "        # mesh grid \n",
        "        xx = torch.arange(0, W).view(1,-1).repeat(H,1)\n",
        "        yy = torch.arange(0, H).view(-1,1).repeat(1,W)\n",
        "        xx = xx.view(1,1,H,W).repeat(B,1,1,1)\n",
        "        yy = yy.view(1,1,H,W).repeat(B,1,1,1)\n",
        "        grid = torch.cat((xx,yy),1).float()\n",
        "       \n",
        "        #x = x.cuda()\n",
        "        #grid = grid.cuda()\n",
        "        vgrid = Variable(grid) + flo # B,2,H,W\n",
        "\n",
        "        vgrid[:,0,:,:] = 2.0*vgrid[:,0,:,:].clone()/max(W-1,1)-1.0 \n",
        "        vgrid[:,1,:,:] = 2.0*vgrid[:,1,:,:].clone()/max(H-1,1)-1.0\n",
        "\n",
        "        \n",
        "        vgrid = vgrid.permute(0,2,3,1)#from B,2,H,W -> B,H,W,2\n",
        "        mask = torch.autograd.Variable(torch.ones(x.size()))\n",
        "        if boolv == 0:\n",
        "          output = torch.nn.functional.grid_sample(x, vgrid,align_corners=True)\n",
        "          mask = torch.nn.functional.grid_sample(mask, vgrid,align_corners=True)\n",
        "        else:\n",
        "          output = torch.nn.functional.grid_sample(x, vgrid,align_corners=True,mode='bicubic')\n",
        "          mask = torch.nn.functional.grid_sample(mask, vgrid,align_corners=True,mode='bicubic')          \n",
        "\n",
        "        mask[mask<0.9999] = 0\n",
        "        mask[mask>0] = 1\n",
        "\n",
        "        return output*mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k_XM8vCE16l"
      },
      "source": [
        "#API\n",
        "def origin(F01, F10, t):\n",
        "  return (1-t)*F01\n",
        "\n",
        "def approx0(F01, F10, t): #Ft0\n",
        "  #t = 1-t\n",
        "  return -(1-t)*t*F01 + t*t*F10\n",
        "\n",
        "def approx1(F01, F10, t): #Ft1\n",
        "  return (1-t)*(1-t)*F01 - t*(1-t)*F10\n",
        "\n",
        "def approxMask(F01, F10, occ_mask_F01, occ_mask_F10, t):\n",
        "  F01 *= np.concatenate([occ_mask_F01[np.newaxis,],occ_mask_F01[np.newaxis,]], axis=0)[np.newaxis,]\n",
        "  F10 *= np.concatenate([occ_mask_F10[np.newaxis,],occ_mask_F10[np.newaxis,]], axis=0)[np.newaxis,]\n",
        "  mask = occ_mask_F01 * occ_mask_F10\n",
        "  maskinv = 1 - mask\n",
        "  return ((F01+F10)*maskinv + ((1-t)*(1-t)*F01 - t*(1-t)*F10)*mask).float()\n",
        "\n",
        "def approxMaskOnlyFilter(F01, F10, occ_mask_F01, occ_mask_F10, t):\n",
        "  F01 *= np.concatenate([occ_mask_F01[np.newaxis,],occ_mask_F01[np.newaxis,]], axis=0)[np.newaxis,]\n",
        "  F10 *= np.concatenate([occ_mask_F10[np.newaxis,],occ_mask_F10[np.newaxis,]], axis=0)[np.newaxis,]\n",
        "  return ((1-t)*(1-t)*F01 - t*(1-t)*F10).float()\n",
        "\n",
        "def integrateIt(I01,I10,img0,img1,t):\n",
        "  I01 = np.transpose(I01.squeeze().numpy(),(1,2,0))\n",
        "  I10 = np.transpose(I10.squeeze().numpy(),(1,2,0))\n",
        "  It = np.zeros(I01.shape).astype(I01.dtype)\n",
        "  \n",
        "  It[I01==0] = I10[I01==0]\n",
        "  It[I10==0] = I01[I10==0]\n",
        "  It[np.logical_and(I01!=0,I10!=0)] = ((1-t)*I10+t*I01)[np.logical_and(I01!=0,I10!=0)]\n",
        "\n",
        "  img0 = np.transpose(img0.squeeze().numpy(), (1,2,0))\n",
        "  img1 = np.transpose(img1.squeeze().numpy(), (1,2,0))\n",
        "  \n",
        "  \n",
        "  if t<0.4:\n",
        "    It[It==0] = img0[It==0]\n",
        "  elif t>0.6:\n",
        "    It[It==0] = img1[It==0]\n",
        "  else:\n",
        "    It[It==0] = ((img0+img1)/2)[It==0]\n",
        "  \n",
        "  return It\n",
        "  \n",
        "\n",
        "def VFI_function(arugments_strFirst, arugments_strSecond, arugments_strPosition, arugments_strOutput, type):\n",
        "  first = os.path.join(arugments_strPosition,arugments_strFirst)\n",
        "  second = os.path.join(arugments_strPosition,arugments_strSecond)\n",
        "  \n",
        "  '''\n",
        "  kernel = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
        "  tenFirst = torch.FloatTensor(np.ascontiguousarray(np.array(PIL.Image.open(first)))[:, :, ::-1].transpose(2, 0, 1).astype(np.float32) * (1.0 / 255.0))\n",
        "  tenSecond = torch.FloatTensor(numpy.ascontiguousarray(np.array(PIL.Image.open(first)))[:, :, ::-1].transpose(2, 0, 1).astype(numpy.float32) * (1.0 / 255.0))\n",
        "  tenOutput = estimate(tenFirst, tenSecond)\n",
        "  tenOutput_2 = estimate(tenSecond, tenFirst)\n",
        "  F01 = tenOutput[np.newaxis,:,:,:]\n",
        "  F10 = tenOutput_2[np.newaxis,:,:,:]\n",
        "  '''\n",
        "  #cv2.filter2D(np.array(PIL.Image.open(first)),-1,kernel)\n",
        "  #cv2.filter2D(np.array(PIL.Image.open(first)),-1,kernel)\n",
        "\n",
        "  F01 = torch.FloatTensor(np.transpose(get_optflow_GMA(first,second),(2,0,1))[np.newaxis])\n",
        "  F10 = torch.FloatTensor(np.transpose(get_optflow_GMA(second,first),(2,0,1))[np.newaxis])\n",
        "\n",
        "  img0 = cv2.imread(first)  \n",
        "  img0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB).astype(np.int32)\n",
        "  img0 = torch.FloatTensor(np.transpose(img0,(2,0,1))[np.newaxis,:,:,:])\n",
        "\n",
        "  img1 = cv2.imread(second) \n",
        "  img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB).astype(np.int32)\n",
        "  img1 = torch.FloatTensor(np.transpose(img1,(2,0,1))[np.newaxis,:,:,:])\n",
        "\n",
        "  #occ_mask_F01, occ_mask_F10 = get_occ_mask(np.transpose(F01.squeeze().numpy(),[1,2,0]), np.transpose(F10.squeeze().numpy(),[1,2,0]))\n",
        "  #F01 *= np.concatenate([occ_mask_F01[np.newaxis,],occ_mask_F01[np.newaxis,]], axis=0)[np.newaxis,]\n",
        "  #F10 *= np.concatenate([occ_mask_F10[np.newaxis,],occ_mask_F10[np.newaxis,]], axis=0)[np.newaxis,]\n",
        "\n",
        "  backwarp = backWarp()\n",
        "  if(type==1.0):\n",
        "    print(\"1st ok\")\n",
        "    t=0.5\n",
        "    I01 = backwarp.forward(img1, approx1(F01,F10,t).float(), 1)\n",
        "    I10 = backwarp.forward(img0, approx0(F01,F10,t).float(), 1) ###approx(F10,F01,t)\n",
        "    test = integrateIt(I01,I10,img0,img1,t)\n",
        "    cv2.imwrite(os.path.join(arugments_strOutput,'frame10i11.jpg'), cv2.cvtColor(test,cv2.COLOR_RGB2BGR))\n",
        "  elif(type==2.0):\n",
        "    idx = int(arugments_strFirst.lstrip('input/').rstrip('.jpg'))\n",
        "    print(\"2nd ok with\", idx)\n",
        "    for i in range(1,8):\n",
        "      t=i/8\n",
        "      I01 = backwarp.forward(img1, approx1(F01,F10,t).float(), 0)\n",
        "      I10 = backwarp.forward(img0, approx0(F01,F10,t).float(), 0)\n",
        "      test = integrateIt(I01,I10,img0,img1,t)\n",
        "      cv2.imwrite(os.path.join(arugments_strOutput,f'{(idx+i):05d}'+'.jpg'), cv2.cvtColor(test,cv2.COLOR_RGB2BGR))\n",
        "  elif(type==3.0):\n",
        "    idx = int(arugments_strFirst.lstrip('input/').rstrip('.jpg'))\n",
        "    print(\"3rd ok with\", idx)\n",
        "    t=0.4\n",
        "    I01 = backwarp.forward(img1, approx1(F01,F10,t).float(), 0)\n",
        "    I10 = backwarp.forward(img0, approx0(F01,F10,t).float(), 0)\n",
        "    test = integrateIt(I01,I10,img0,img1,t)\n",
        "    cv2.imwrite(os.path.join(arugments_strOutput,f'{(idx+4):05d}'+'.jpg'), cv2.cvtColor(test,cv2.COLOR_RGB2BGR))\n",
        "    t=0.8\n",
        "    I01 = backwarp.forward(img1, approx1(F01,F10,t).float(), 0)\n",
        "    I10 = backwarp.forward(img0, approx0(F01,F10,t).float(), 0)\n",
        "    test = integrateIt(I01,I10,img0,img1,t)\n",
        "    cv2.imwrite(os.path.join(arugments_strOutput,f'{(idx+8):05d}'+'.jpg'), cv2.cvtColor(test,cv2.COLOR_RGB2BGR))\n",
        "  elif(type==4.0):\n",
        "    idx = int(arugments_strFirst.lstrip('input/').rstrip('.jpg'))\n",
        "    print(\"4th ok with\", idx)\n",
        "    t=0.2\n",
        "    I01 = backwarp.forward(img1, approx1(F01,F10,t).float(), 0)\n",
        "    I10 = backwarp.forward(img0, approx0(F01,F10,t).float(), 0)\n",
        "    test = integrateIt(I01,I10,img0,img1,t)\n",
        "    cv2.imwrite(os.path.join(arugments_strOutput,f'{(idx+2):05d}'+'.jpg'), cv2.cvtColor(test,cv2.COLOR_RGB2BGR))\n",
        "    t=0.6\n",
        "    I01 = backwarp.forward(img1, approx1(F01,F10,t).float(), 0)\n",
        "    I10 = backwarp.forward(img0, approx0(F01,F10,t).float(), 0)\n",
        "    test = integrateIt(I01,I10,img0,img1,t)\n",
        "    cv2.imwrite(os.path.join(arugments_strOutput,f'{(idx+6):05d}'+'.jpg'), cv2.cvtColor(test,cv2.COLOR_RGB2BGR))\n",
        "  else:\n",
        "    print(\"error\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdvbZiERGZ8N",
        "outputId": "1902c9cc-2db3-4bd8-ae1c-04fc96fe6226"
      },
      "source": [
        "# #testing\n",
        "from pathlib import Path\n",
        "\n",
        "for i in range(7,17):\n",
        "  dir = os.path.join(task_1_dir,\"{}\".format(i)) #'1_30fps_to_240fps/3/0/'\n",
        "  out =  os.path.join(task_1_output,\"{}\".format(i))  #'1_30fps_to_240fps/3/0/'\n",
        "  Path(out).mkdir(parents=True, exist_ok=True)\n",
        "  first = 'input/frame10.png'              #'0_center_frame/7/input/frame10.png'\n",
        "  second = 'input/frame11.png'             #'0_center_frame/7/input/frame11.png'\n",
        "  VFI_function(first, second, dir, out, 1)\n",
        "\n",
        "#output file with '1_30fps_to_240fps/'\n",
        "\n",
        "\n",
        "for i in range(3,5):\n",
        "  for j in range(12):\n",
        "    dir = os.path.join(task_2_dir,\"{}\".format(i),\"{}\".format(j)) #'1_30fps_to_240fps/3/0/'\n",
        "    out =  os.path.join(task_2_output,\"{}\".format(i),\"{}\".format(j))  #'1_30fps_to_240fps/3/0/'\n",
        "    Path(out).mkdir(parents=True, exist_ok=True)\n",
        "    first = 'input/' + f'{(8*j):05d}' + '.jpg'       #'1_30fps_to_240fps/3/0/input/00000.jpg'\n",
        "    second = 'input/' + f'{(8*(j+1)):05d}' + '.jpg'     #'1_30fps_to_240fps/3/0/input/00008.jpg'\n",
        "    VFI_function(first, second, dir, out, 2)\n",
        "\n",
        "#output file with 2_24fps_to_60fps/'\n",
        "for i in range(3,5):\n",
        "  for j in range(8):\n",
        "    dir = os.path.join(task_3_dir,\"{}\".format(i),\"{}\".format(j)) #'1_30fps_to_240fps/3/0/'\n",
        "    out =  os.path.join(task_3_output,\"{}\".format(i),\"{}\".format(j))  #'1_30fps_to_240fps/3/0/'\n",
        "    Path(out).mkdir(parents=True, exist_ok=True)\n",
        "    first = 'input/' + f'{(10*j):05d}' + '.jpg'       #'1_30fps_to_240fps/3/0/input/00000.jpg'\n",
        "    second = 'input/' + f'{(10*(j+1)):05d}' + '.jpg'     #'1_30fps_to_240fps/3/0/input/00008.jpg'\n",
        "    VFI_function(first, second, dir, out, 3+j%2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1st ok\n",
            "1st ok\n",
            "1st ok\n",
            "1st ok\n",
            "1st ok\n",
            "2nd ok with 0\n",
            "2nd ok with 8\n",
            "2nd ok with 16\n",
            "2nd ok with 24\n",
            "2nd ok with 32\n",
            "2nd ok with 40\n",
            "2nd ok with 48\n",
            "2nd ok with 56\n",
            "2nd ok with 64\n",
            "2nd ok with 72\n",
            "2nd ok with 80\n",
            "2nd ok with 88\n",
            "2nd ok with 0\n",
            "2nd ok with 8\n",
            "2nd ok with 16\n",
            "2nd ok with 24\n",
            "2nd ok with 32\n",
            "2nd ok with 40\n",
            "2nd ok with 48\n",
            "2nd ok with 56\n",
            "2nd ok with 64\n",
            "2nd ok with 72\n",
            "2nd ok with 80\n",
            "2nd ok with 88\n",
            "3rd ok with 0\n",
            "4th ok with 10\n",
            "3rd ok with 20\n",
            "4th ok with 30\n",
            "3rd ok with 40\n",
            "4th ok with 50\n",
            "3rd ok with 60\n",
            "4th ok with 70\n",
            "3rd ok with 0\n",
            "4th ok with 10\n",
            "3rd ok with 20\n",
            "4th ok with 30\n",
            "3rd ok with 40\n",
            "4th ok with 50\n",
            "3rd ok with 60\n",
            "4th ok with 70\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}